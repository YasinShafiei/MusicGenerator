{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b475be42",
   "metadata": {},
   "source": [
    "### Import libraries and define vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e189fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "from music21 import *\n",
    "from keras.layers import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import keras.backend as K\n",
    "from keras.callbacks import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99482ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables and hyperparameters\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 256\n",
    "DATA_PATH = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf2f9ab",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87127f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(file):\n",
    "    \"\"\"\n",
    "    This function will read midi files and return all of it notes\n",
    "    \"\"\"\n",
    "    # define list for notes and variable for notes to parse\n",
    "    notes = list()\n",
    "    notes_to_parse = None\n",
    "\n",
    "    # read midi files\n",
    "    midi = converter.parse(file)\n",
    "\n",
    "    # Seperate instruments\n",
    "    instruments = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    # loop over all instruments\n",
    "    for part in instruments.parts:\n",
    "        # select only piano notes\n",
    "        if \"Piano\" in str(part):\n",
    "            notes_to_parse = part.recurse()\n",
    "\n",
    "            # find if the element is chord or single note\n",
    "            for element in notes_to_parse:\n",
    "                # to select notes\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "\n",
    "                # to select chords\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "\n",
    "    # put notes into an array\n",
    "    notes_array = np.array(notes)\n",
    "\n",
    "    return notes_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e17da5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasin\\AppData\\Local\\Temp\\ipykernel_2424\\2770618029.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  notes_array = np.array([read_midi(DATA_PATH + i) for i in files])\n"
     ]
    }
   ],
   "source": [
    "# read all of the file names\n",
    "files=[i for i in os.listdir(DATA_PATH) if i.endswith(\".mid\")]\n",
    "\n",
    "# load the musics\n",
    "notes_array = np.array([read_midi(DATA_PATH + i) for i in files])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7831bdf",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b420f44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1226 unique notes.\n"
     ]
    }
   ],
   "source": [
    "# converting 2D array into 1D array\n",
    "notes_1d = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "# get number if unique notes\n",
    "unique_notes = list(set(notes_1d))\n",
    "\n",
    "print(f\"We have {len(unique_notes)} unique notes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61410cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 383 frequent notes.\n"
     ]
    }
   ],
   "source": [
    "# see how many frequent notes we have \n",
    "frequent = dict(Counter(notes_1d))\n",
    "frequent_notes = [note_ for note_, count in frequent.items() if count>=50]\n",
    "\n",
    "print(f\"We have {len(frequent_notes)} frequent notes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39361517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasin\\AppData\\Local\\Temp\\ipykernel_2424\\2819184097.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  new_music = np.array(new_music)\n"
     ]
    }
   ],
   "source": [
    "# define list for new music\n",
    "new_music = list()\n",
    "\n",
    "# Add all frequent notes into new music\n",
    "for notes in notes_array:\n",
    "    temp = list()\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)\n",
    "\n",
    "    new_music.append(temp)\n",
    "\n",
    "# convert new music into numpy array\n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "017eb618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variable for X, y and number of timesteps\n",
    "n_timesteps = 32\n",
    "X = list()\n",
    "y = list()\n",
    "\n",
    "# loop over all notes in new music\n",
    "for notes in new_music:\n",
    "    for i in range(0, len(notes) - n_timesteps, 1):\n",
    "\n",
    "        # prepare input and output\n",
    "        input_data = notes[i:i + n_timesteps]\n",
    "        output_data = notes[i + n_timesteps]\n",
    "\n",
    "        # add input and output data in to X and y lists\n",
    "        X.append(input_data)\n",
    "        y.append(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b37e8eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert X and y into numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c32419ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign int numbers into each frequent note\n",
    "unique_x = list(set(X.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe1c788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input seauence \n",
    "x_sequence = list()\n",
    "\n",
    "for i in X:\n",
    "    temp = list()\n",
    "    for j in i:\n",
    "        temp.append(x_note_to_int[j])\n",
    "    \n",
    "    x_sequence.append(temp)\n",
    "\n",
    "x_sequence = np.array(x_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99ee48da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprare output data\n",
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_sequence = np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6562ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test \n",
    "train_input, val_input, train_output, val_output = train_test_split(x_sequence,\n",
    "                                                                    y_sequence,\n",
    "                                                                    test_size=0.2,\n",
    "                                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44d192b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data into numpy arrays\n",
    "train_input = np.array(train_input)\n",
    "train_output = np.array(train_output)\n",
    "val_input = np.array(val_input)\n",
    "val_output = np.array(val_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451a24ca",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bad21a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input and output shapes\n",
    "input_shape = len(unique_x)\n",
    "output_shape = len(unique_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "4d1f4c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "    \n",
    "# input layer\n",
    "model.add(Embedding(input_shape, 100, input_length=32, trainable=True)) \n",
    "\n",
    "# Conv block 1\n",
    "model.add(Conv1D(64, 3, padding='causal', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "# Conv block 2\n",
    "model.add(Conv1D(128, 3, dilation_rate=2, padding='causal', activation='relu',))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "# Conv block 3\n",
    "model.add(Conv1D(256, 3, dilation_rate=4,padding='causal', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "# Global maxPooling\n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "# Dense layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(output_shape, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "e0504eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "7ed1248a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 32, 100)           38300     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 32, 64)            19264     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 64)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 16, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 8, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 8, 256)            98560     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 4, 256)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 256)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 383)               98431     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410,843\n",
      "Trainable params: 410,843\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# see the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "a1d86a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_back = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "9f6afc22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2667/2671 [============================>.] - ETA: 0s - loss: 4.2674\n",
      "Epoch 1: val_loss improved from inf to 4.12488, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 22s 8ms/step - loss: 4.2670 - val_loss: 4.1249\n",
      "Epoch 2/100\n",
      "2671/2671 [==============================] - ETA: 0s - loss: 3.9161\n",
      "Epoch 2: val_loss improved from 4.12488 to 3.93774, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.9161 - val_loss: 3.9377\n",
      "Epoch 3/100\n",
      "2663/2671 [============================>.] - ETA: 0s - loss: 3.8131\n",
      "Epoch 3: val_loss improved from 3.93774 to 3.84919, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.8129 - val_loss: 3.8492\n",
      "Epoch 4/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.7557\n",
      "Epoch 4: val_loss improved from 3.84919 to 3.80118, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.7556 - val_loss: 3.8012\n",
      "Epoch 5/100\n",
      "2668/2671 [============================>.] - ETA: 0s - loss: 3.7171\n",
      "Epoch 5: val_loss improved from 3.80118 to 3.73775, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.7169 - val_loss: 3.7378\n",
      "Epoch 6/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.6867\n",
      "Epoch 6: val_loss improved from 3.73775 to 3.73165, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.6868 - val_loss: 3.7316\n",
      "Epoch 7/100\n",
      "2667/2671 [============================>.] - ETA: 0s - loss: 3.6609\n",
      "Epoch 7: val_loss improved from 3.73165 to 3.68692, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 22s 8ms/step - loss: 3.6608 - val_loss: 3.6869\n",
      "Epoch 8/100\n",
      "2667/2671 [============================>.] - ETA: 0s - loss: 3.6442\n",
      "Epoch 8: val_loss improved from 3.68692 to 3.68677, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 22s 8ms/step - loss: 3.6444 - val_loss: 3.6868\n",
      "Epoch 9/100\n",
      "2666/2671 [============================>.] - ETA: 0s - loss: 3.6284\n",
      "Epoch 9: val_loss improved from 3.68677 to 3.68046, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.6284 - val_loss: 3.6805\n",
      "Epoch 10/100\n",
      "2671/2671 [==============================] - ETA: 0s - loss: 3.6161\n",
      "Epoch 10: val_loss improved from 3.68046 to 3.65900, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.6161 - val_loss: 3.6590\n",
      "Epoch 11/100\n",
      "2667/2671 [============================>.] - ETA: 0s - loss: 3.6041\n",
      "Epoch 11: val_loss improved from 3.65900 to 3.65110, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 22s 8ms/step - loss: 3.6040 - val_loss: 3.6511\n",
      "Epoch 12/100\n",
      "2671/2671 [==============================] - ETA: 0s - loss: 3.5943\n",
      "Epoch 12: val_loss improved from 3.65110 to 3.64606, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5943 - val_loss: 3.6461\n",
      "Epoch 13/100\n",
      "2668/2671 [============================>.] - ETA: 0s - loss: 3.5866\n",
      "Epoch 13: val_loss improved from 3.64606 to 3.62865, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.5866 - val_loss: 3.6286\n",
      "Epoch 14/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.5775\n",
      "Epoch 14: val_loss improved from 3.62865 to 3.62613, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5775 - val_loss: 3.6261\n",
      "Epoch 15/100\n",
      "2667/2671 [============================>.] - ETA: 0s - loss: 3.5724\n",
      "Epoch 15: val_loss improved from 3.62613 to 3.61551, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.5724 - val_loss: 3.6155\n",
      "Epoch 16/100\n",
      "2666/2671 [============================>.] - ETA: 0s - loss: 3.5671\n",
      "Epoch 16: val_loss improved from 3.61551 to 3.60747, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.5670 - val_loss: 3.6075\n",
      "Epoch 17/100\n",
      "2671/2671 [==============================] - ETA: 0s - loss: 3.5611\n",
      "Epoch 17: val_loss improved from 3.60747 to 3.60649, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.5611 - val_loss: 3.6065\n",
      "Epoch 18/100\n",
      "2669/2671 [============================>.] - ETA: 0s - loss: 3.5556\n",
      "Epoch 18: val_loss improved from 3.60649 to 3.59746, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.5557 - val_loss: 3.5975\n",
      "Epoch 19/100\n",
      "2663/2671 [============================>.] - ETA: 0s - loss: 3.5527\n",
      "Epoch 19: val_loss did not improve from 3.59746\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.5527 - val_loss: 3.5983\n",
      "Epoch 20/100\n",
      "2669/2671 [============================>.] - ETA: 0s - loss: 3.5474\n",
      "Epoch 20: val_loss improved from 3.59746 to 3.59189, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.5475 - val_loss: 3.5919\n",
      "Epoch 21/100\n",
      "2669/2671 [============================>.] - ETA: 0s - loss: 3.5448\n",
      "Epoch 21: val_loss improved from 3.59189 to 3.58881, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5448 - val_loss: 3.5888\n",
      "Epoch 22/100\n",
      "2664/2671 [============================>.] - ETA: 0s - loss: 3.5399\n",
      "Epoch 22: val_loss improved from 3.58881 to 3.58279, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5399 - val_loss: 3.5828\n",
      "Epoch 23/100\n",
      "2665/2671 [============================>.] - ETA: 0s - loss: 3.5375\n",
      "Epoch 23: val_loss did not improve from 3.58279\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.5377 - val_loss: 3.5960\n",
      "Epoch 24/100\n",
      "2663/2671 [============================>.] - ETA: 0s - loss: 3.5344\n",
      "Epoch 24: val_loss did not improve from 3.58279\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5343 - val_loss: 3.5830\n",
      "Epoch 25/100\n",
      "2665/2671 [============================>.] - ETA: 0s - loss: 3.5319\n",
      "Epoch 25: val_loss improved from 3.58279 to 3.57839, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5318 - val_loss: 3.5784\n",
      "Epoch 26/100\n",
      "2666/2671 [============================>.] - ETA: 0s - loss: 3.5303\n",
      "Epoch 26: val_loss improved from 3.57839 to 3.57553, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5304 - val_loss: 3.5755\n",
      "Epoch 27/100\n",
      "2664/2671 [============================>.] - ETA: 0s - loss: 3.5285\n",
      "Epoch 27: val_loss did not improve from 3.57553\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5284 - val_loss: 3.5789\n",
      "Epoch 28/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.5242\n",
      "Epoch 28: val_loss improved from 3.57553 to 3.57530, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5242 - val_loss: 3.5753\n",
      "Epoch 29/100\n",
      "2669/2671 [============================>.] - ETA: 0s - loss: 3.5224\n",
      "Epoch 29: val_loss improved from 3.57530 to 3.56248, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5224 - val_loss: 3.5625\n",
      "Epoch 30/100\n",
      "2664/2671 [============================>.] - ETA: 0s - loss: 3.5201\n",
      "Epoch 30: val_loss did not improve from 3.56248\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5202 - val_loss: 3.5818\n",
      "Epoch 31/100\n",
      "2664/2671 [============================>.] - ETA: 0s - loss: 3.5170\n",
      "Epoch 31: val_loss did not improve from 3.56248\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.5170 - val_loss: 3.5632\n",
      "Epoch 32/100\n",
      "2668/2671 [============================>.] - ETA: 0s - loss: 3.5166\n",
      "Epoch 32: val_loss improved from 3.56248 to 3.56050, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.5167 - val_loss: 3.5605\n",
      "Epoch 33/100\n",
      "2669/2671 [============================>.] - ETA: 0s - loss: 3.5137\n",
      "Epoch 33: val_loss did not improve from 3.56050\n",
      "2671/2671 [==============================] - 20s 7ms/step - loss: 3.5137 - val_loss: 3.5674\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2667/2671 [============================>.] - ETA: 0s - loss: 3.5125\n",
      "Epoch 34: val_loss improved from 3.56050 to 3.55144, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 20s 7ms/step - loss: 3.5124 - val_loss: 3.5514\n",
      "Epoch 35/100\n",
      "2669/2671 [============================>.] - ETA: 0s - loss: 3.5103\n",
      "Epoch 35: val_loss did not improve from 3.55144\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5104 - val_loss: 3.5565\n",
      "Epoch 36/100\n",
      "2668/2671 [============================>.] - ETA: 0s - loss: 3.5074\n",
      "Epoch 36: val_loss did not improve from 3.55144\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5075 - val_loss: 3.5579\n",
      "Epoch 37/100\n",
      "2664/2671 [============================>.] - ETA: 0s - loss: 3.5084\n",
      "Epoch 37: val_loss did not improve from 3.55144\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5085 - val_loss: 3.5563\n",
      "Epoch 38/100\n",
      "2668/2671 [============================>.] - ETA: 0s - loss: 3.5062\n",
      "Epoch 38: val_loss did not improve from 3.55144\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5062 - val_loss: 3.5549\n",
      "Epoch 39/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.5057\n",
      "Epoch 39: val_loss did not improve from 3.55144\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5057 - val_loss: 3.5612\n",
      "Epoch 40/100\n",
      "2671/2671 [==============================] - ETA: 0s - loss: 3.5055\n",
      "Epoch 40: val_loss improved from 3.55144 to 3.54856, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5055 - val_loss: 3.5486\n",
      "Epoch 41/100\n",
      "2667/2671 [============================>.] - ETA: 0s - loss: 3.5022\n",
      "Epoch 41: val_loss improved from 3.54856 to 3.54460, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5022 - val_loss: 3.5446\n",
      "Epoch 42/100\n",
      "2664/2671 [============================>.] - ETA: 0s - loss: 3.5016\n",
      "Epoch 42: val_loss did not improve from 3.54460\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.5015 - val_loss: 3.5486\n",
      "Epoch 43/100\n",
      "2665/2671 [============================>.] - ETA: 0s - loss: 3.4996\n",
      "Epoch 43: val_loss did not improve from 3.54460\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4998 - val_loss: 3.5621\n",
      "Epoch 44/100\n",
      "2664/2671 [============================>.] - ETA: 0s - loss: 3.4975\n",
      "Epoch 44: val_loss did not improve from 3.54460\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4977 - val_loss: 3.5559\n",
      "Epoch 45/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.4977\n",
      "Epoch 45: val_loss did not improve from 3.54460\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4977 - val_loss: 3.5477\n",
      "Epoch 46/100\n",
      "2667/2671 [============================>.] - ETA: 0s - loss: 3.4983\n",
      "Epoch 46: val_loss did not improve from 3.54460\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4982 - val_loss: 3.5534\n",
      "Epoch 47/100\n",
      "2664/2671 [============================>.] - ETA: 0s - loss: 3.4956\n",
      "Epoch 47: val_loss did not improve from 3.54460\n",
      "2671/2671 [==============================] - 20s 7ms/step - loss: 3.4956 - val_loss: 3.5473\n",
      "Epoch 48/100\n",
      "2665/2671 [============================>.] - ETA: 0s - loss: 3.4955\n",
      "Epoch 48: val_loss improved from 3.54460 to 3.54026, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.4955 - val_loss: 3.5403\n",
      "Epoch 49/100\n",
      "2662/2671 [============================>.] - ETA: 0s - loss: 3.4947\n",
      "Epoch 49: val_loss did not improve from 3.54026\n",
      "2671/2671 [==============================] - 20s 7ms/step - loss: 3.4948 - val_loss: 3.5510\n",
      "Epoch 50/100\n",
      "2666/2671 [============================>.] - ETA: 0s - loss: 3.4937\n",
      "Epoch 50: val_loss did not improve from 3.54026\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.4937 - val_loss: 3.5509\n",
      "Epoch 51/100\n",
      "2666/2671 [============================>.] - ETA: 0s - loss: 3.4946\n",
      "Epoch 51: val_loss improved from 3.54026 to 3.53879, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4946 - val_loss: 3.5388\n",
      "Epoch 52/100\n",
      "2668/2671 [============================>.] - ETA: 0s - loss: 3.4919\n",
      "Epoch 52: val_loss did not improve from 3.53879\n",
      "2671/2671 [==============================] - 20s 7ms/step - loss: 3.4919 - val_loss: 3.5527\n",
      "Epoch 53/100\n",
      "2663/2671 [============================>.] - ETA: 0s - loss: 3.4918\n",
      "Epoch 53: val_loss did not improve from 3.53879\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4919 - val_loss: 3.5436\n",
      "Epoch 54/100\n",
      "2664/2671 [============================>.] - ETA: 0s - loss: 3.4896\n",
      "Epoch 54: val_loss did not improve from 3.53879\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.4898 - val_loss: 3.5411\n",
      "Epoch 55/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.4899\n",
      "Epoch 55: val_loss did not improve from 3.53879\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.4899 - val_loss: 3.5483\n",
      "Epoch 56/100\n",
      "2667/2671 [============================>.] - ETA: 0s - loss: 3.4902\n",
      "Epoch 56: val_loss improved from 3.53879 to 3.53509, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4902 - val_loss: 3.5351\n",
      "Epoch 57/100\n",
      "2664/2671 [============================>.] - ETA: 0s - loss: 3.4882\n",
      "Epoch 57: val_loss did not improve from 3.53509\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4881 - val_loss: 3.5490\n",
      "Epoch 58/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.4877\n",
      "Epoch 58: val_loss did not improve from 3.53509\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.4876 - val_loss: 3.5470\n",
      "Epoch 59/100\n",
      "2671/2671 [==============================] - ETA: 0s - loss: 3.4873\n",
      "Epoch 59: val_loss did not improve from 3.53509\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4873 - val_loss: 3.5548\n",
      "Epoch 60/100\n",
      "2667/2671 [============================>.] - ETA: 0s - loss: 3.4868\n",
      "Epoch 60: val_loss did not improve from 3.53509\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.4868 - val_loss: 3.5568\n",
      "Epoch 61/100\n",
      "2667/2671 [============================>.] - ETA: 0s - loss: 3.4878\n",
      "Epoch 61: val_loss did not improve from 3.53509\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.4879 - val_loss: 3.5514\n",
      "Epoch 62/100\n",
      "2668/2671 [============================>.] - ETA: 0s - loss: 3.4850\n",
      "Epoch 62: val_loss did not improve from 3.53509\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.4850 - val_loss: 3.5458\n",
      "Epoch 63/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.4845\n",
      "Epoch 63: val_loss did not improve from 3.53509\n",
      "2671/2671 [==============================] - 20s 7ms/step - loss: 3.4845 - val_loss: 3.5434\n",
      "Epoch 64/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.4841\n",
      "Epoch 64: val_loss did not improve from 3.53509\n",
      "2671/2671 [==============================] - 20s 7ms/step - loss: 3.4841 - val_loss: 3.5468\n",
      "Epoch 65/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.4844\n",
      "Epoch 65: val_loss did not improve from 3.53509\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4844 - val_loss: 3.5500\n",
      "Epoch 66/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.4842\n",
      "Epoch 66: val_loss did not improve from 3.53509\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.4842 - val_loss: 3.5434\n",
      "Epoch 67/100\n",
      "2671/2671 [==============================] - ETA: 0s - loss: 3.4836\n",
      "Epoch 67: val_loss did not improve from 3.53509\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.4836 - val_loss: 3.5459\n",
      "Epoch 68/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.4824\n",
      "Epoch 68: val_loss did not improve from 3.53509\n",
      "2671/2671 [==============================] - 20s 7ms/step - loss: 3.4824 - val_loss: 3.5578\n",
      "Epoch 69/100\n",
      "2668/2671 [============================>.] - ETA: 0s - loss: 3.4833\n",
      "Epoch 69: val_loss improved from 3.53509 to 3.53366, saving model to best_model.h5\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4833 - val_loss: 3.5337\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2669/2671 [============================>.] - ETA: 0s - loss: 3.4823\n",
      "Epoch 70: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 20s 7ms/step - loss: 3.4824 - val_loss: 3.5516\n",
      "Epoch 71/100\n",
      "2666/2671 [============================>.] - ETA: 0s - loss: 3.4824\n",
      "Epoch 71: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 20s 7ms/step - loss: 3.4825 - val_loss: 3.5365\n",
      "Epoch 72/100\n",
      "2669/2671 [============================>.] - ETA: 0s - loss: 3.4793\n",
      "Epoch 72: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4794 - val_loss: 3.5537\n",
      "Epoch 73/100\n",
      "2667/2671 [============================>.] - ETA: 0s - loss: 3.4793\n",
      "Epoch 73: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4794 - val_loss: 3.5461\n",
      "Epoch 74/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.4784\n",
      "Epoch 74: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4784 - val_loss: 3.5415\n",
      "Epoch 75/100\n",
      "2668/2671 [============================>.] - ETA: 0s - loss: 3.4799\n",
      "Epoch 75: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.4799 - val_loss: 3.5415\n",
      "Epoch 76/100\n",
      "2669/2671 [============================>.] - ETA: 0s - loss: 3.4774\n",
      "Epoch 76: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.4775 - val_loss: 3.5438\n",
      "Epoch 77/100\n",
      "2671/2671 [==============================] - ETA: 0s - loss: 3.4790\n",
      "Epoch 77: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 20s 8ms/step - loss: 3.4790 - val_loss: 3.5432\n",
      "Epoch 78/100\n",
      "2668/2671 [============================>.] - ETA: 0s - loss: 3.4798\n",
      "Epoch 78: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4798 - val_loss: 3.5415\n",
      "Epoch 79/100\n",
      "2671/2671 [==============================] - ETA: 0s - loss: 3.4788\n",
      "Epoch 79: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4788 - val_loss: 3.5456\n",
      "Epoch 80/100\n",
      "2666/2671 [============================>.] - ETA: 0s - loss: 3.4768\n",
      "Epoch 80: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4770 - val_loss: 3.5448\n",
      "Epoch 81/100\n",
      "2668/2671 [============================>.] - ETA: 0s - loss: 3.4774\n",
      "Epoch 81: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4774 - val_loss: 3.5454\n",
      "Epoch 82/100\n",
      "2666/2671 [============================>.] - ETA: 0s - loss: 3.4788\n",
      "Epoch 82: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4789 - val_loss: 3.5353\n",
      "Epoch 83/100\n",
      "2671/2671 [==============================] - ETA: 0s - loss: 3.4787\n",
      "Epoch 83: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 22s 8ms/step - loss: 3.4787 - val_loss: 3.5498\n",
      "Epoch 84/100\n",
      "2669/2671 [============================>.] - ETA: 0s - loss: 3.4780\n",
      "Epoch 84: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 22s 8ms/step - loss: 3.4780 - val_loss: 3.5420\n",
      "Epoch 85/100\n",
      "2665/2671 [============================>.] - ETA: 0s - loss: 3.4762\n",
      "Epoch 85: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 22s 8ms/step - loss: 3.4762 - val_loss: 3.5413\n",
      "Epoch 86/100\n",
      "2663/2671 [============================>.] - ETA: 0s - loss: 3.4771\n",
      "Epoch 86: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 22s 8ms/step - loss: 3.4772 - val_loss: 3.5404\n",
      "Epoch 87/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.4760\n",
      "Epoch 87: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4760 - val_loss: 3.5404\n",
      "Epoch 88/100\n",
      "2663/2671 [============================>.] - ETA: 0s - loss: 3.4738\n",
      "Epoch 88: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4739 - val_loss: 3.5438\n",
      "Epoch 89/100\n",
      "2664/2671 [============================>.] - ETA: 0s - loss: 3.4754\n",
      "Epoch 89: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4754 - val_loss: 3.5408\n",
      "Epoch 90/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.4762\n",
      "Epoch 90: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4762 - val_loss: 3.5344\n",
      "Epoch 91/100\n",
      "2671/2671 [==============================] - ETA: 0s - loss: 3.4757\n",
      "Epoch 91: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4757 - val_loss: 3.5402\n",
      "Epoch 92/100\n",
      "2665/2671 [============================>.] - ETA: 0s - loss: 3.4737\n",
      "Epoch 92: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4738 - val_loss: 3.5397\n",
      "Epoch 93/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.4743\n",
      "Epoch 93: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4743 - val_loss: 3.5468\n",
      "Epoch 94/100\n",
      "2671/2671 [==============================] - ETA: 0s - loss: 3.4748\n",
      "Epoch 94: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4748 - val_loss: 3.5468\n",
      "Epoch 95/100\n",
      "2666/2671 [============================>.] - ETA: 0s - loss: 3.4731\n",
      "Epoch 95: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4732 - val_loss: 3.5339\n",
      "Epoch 96/100\n",
      "2664/2671 [============================>.] - ETA: 0s - loss: 3.4742\n",
      "Epoch 96: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4742 - val_loss: 3.5398\n",
      "Epoch 97/100\n",
      "2666/2671 [============================>.] - ETA: 0s - loss: 3.4736\n",
      "Epoch 97: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 21s 8ms/step - loss: 3.4735 - val_loss: 3.5389\n",
      "Epoch 98/100\n",
      "2670/2671 [============================>.] - ETA: 0s - loss: 3.4736\n",
      "Epoch 98: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 22s 8ms/step - loss: 3.4736 - val_loss: 3.5398\n",
      "Epoch 99/100\n",
      "2667/2671 [============================>.] - ETA: 0s - loss: 3.4735\n",
      "Epoch 99: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 22s 8ms/step - loss: 3.4735 - val_loss: 3.5377\n",
      "Epoch 100/100\n",
      "2667/2671 [============================>.] - ETA: 0s - loss: 3.4736\n",
      "Epoch 100: val_loss did not improve from 3.53366\n",
      "2671/2671 [==============================] - 22s 8ms/step - loss: 3.4736 - val_loss: 3.5414\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(train_input,\n",
    "                    train_output,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(val_input, val_output),\n",
    "                    verbose=1,\n",
    "                    callbacks=[call_back])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1ebef7",
   "metadata": {},
   "source": [
    "### Load model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0b8718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5526b636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "# define a list for prediction\n",
    "prediction_list = list()\n",
    "\n",
    "# define index\n",
    "index = np.random.randint(0, len(train_input) - 1)\n",
    "# define random music\n",
    "random_music = train_input[index]\n",
    "\n",
    "for i in range(10):\n",
    "    random_music = random_music.reshape(1, 32)\n",
    "    # make prediction\n",
    "    prediction = model.predict(random_music)[0]\n",
    "    y_prediction = np.argmax(prediction, axis=0)\n",
    "    prediction_list.append(y_prediction)\n",
    "    \n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_prediction)\n",
    "    random_music = random_music[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6ee8ae4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([218, 158, 247, 158,  51, 374, 247, 374, 289, 374, 164, 152, 247,\n",
       "       152, 249, 337, 218, 158, 247, 158,  51, 374,  67, 374, 374, 374,\n",
       "       374, 374, 374, 374, 374, 374])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "164006b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67, 374, 374, 374, 374, 374, 374, 374, 374, 374]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "id": "488cfe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert prediction to notes'\n",
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in prediction_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585d8b10",
   "metadata": {},
   "source": [
    "### Convert prediction to midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "id": "2d46e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output, music_name):\n",
    "    \"\"\"\n",
    "    This function will convert notes into midi file\n",
    "    \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp=music_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "id": "8a452d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes, 'music_8.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a509657f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
